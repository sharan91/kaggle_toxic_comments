{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "f8f14bc0-147e-413b-979c-eb7685b4e7fd",
        "_uuid": "a2ae0ed48fb43f309140c8d636b6d0f7c8bf32c9",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import cross_val_score\nimport scipy\nfrom scipy.sparse import hstack\nfrom scipy.special import logit, expit\nfrom sklearn.svm import SVC\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "b265a3cf-9cc3-4d7b-aaba-7795093b064f",
        "collapsed": true,
        "_uuid": "899ec788dd9c15677753109b4dd46f643ea3b185",
        "trusted": false
      },
      "cell_type": "code",
      "source": "df_train = pd.read_csv('../input/train.csv').fillna(' ')\ndf_test = pd.read_csv('../input/test.csv').fillna(' ')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "bb8fb15a-4dd6-461d-9d62-799559b24bc1",
        "collapsed": true,
        "_uuid": "55b185ced17f7b1d99e9d33c7b8850552323216a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "df = pd.concat([df_train, df_test], 0)\nnrow_train = df_train.shape[0]\nclass_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "75f96e9c-2e5d-4ef3-8b1f-ba89368840ad",
        "collapsed": true,
        "_uuid": "f4fe2bc4cdf56df5daba87f9f305b00e7523b6ff",
        "trusted": false
      },
      "cell_type": "code",
      "source": "df['loglen'] = np.log1p(df['comment_text'].str.len())\nloglen = scipy.sparse.csr_matrix(df['loglen'].values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "ad7b7a29-613c-4fdb-b2c2-03c2206733f2",
        "collapsed": true,
        "_uuid": "ea31f6e8fd006c8369f92c263b91c6101c1fb55c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "word_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    ngram_range=(1, 1),\n    max_features=10000)\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    ngram_range=(1, 5),\n    max_features=20000)\nwords = word_vectorizer.fit_transform(df['comment_text'])\nchars = char_vectorizer.fit_transform(df['comment_text'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "5af2e4cb-7290-4b5e-a37f-d1320f3f9e15",
        "collapsed": true,
        "_uuid": "b7f9b66c6d3130d1326ec7870b10a8b5a74a91a9",
        "trusted": false
      },
      "cell_type": "code",
      "source": "X = scipy.sparse.hstack((words, \n                         chars,\n                         loglen.transpose())).tocsr()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "de3a7952-8763-416a-8fff-6ad0a3fc65e2",
        "collapsed": true,
        "_uuid": "c1f9381c73b557cc2536e69339809ee815ce433c",
        "trusted": false
      },
      "cell_type": "code",
      "source": "X_train = X[:nrow_train]\nX_test = X[nrow_train:]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "453070aa2f45f67d8f9c53e142f90fcd30afbcd1",
        "_cell_guid": "c7caedee-4a81-413f-97ef-6d73831c160a",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#testing\nlosses_log = []\nlosses_nb = []\nfor class_name in class_names:\n    train_target = df_train[class_name]\n    classifier = LogisticRegression()\n\n    cv_loss = np.mean(cross_val_score(classifier, X_train, train_target, cv=3, scoring='roc_auc'))\n    losses_log.append(cv_loss)\n    print('Logit CV score for class {} is {}'.format(class_name, cv_loss))\n\nprint('Total CV score is {}'.format(np.mean(losses_log + losses_nb)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ded0771bdad4cd3c654dc916caffa5ffe9b02f35",
        "_cell_guid": "9b14afb6-6166-497a-a1b7-70574754a5c8",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "predictions = {'id': df_test['id']}\nfor class_name in class_names:\n    train_target = df_train[class_name]\n    classifier_log = LogisticRegression(solver='sag')\n\n    classifier_log.fit(X_train, train_target)\n    predictions[class_name] = classifier_log.predict_proba(X_test)[:,1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "e438f055-28cf-4f21-945c-8b8d3a989371",
        "collapsed": true,
        "_uuid": "2db33ae7fe8d041d367290c7d0d7824da0f11245",
        "trusted": false
      },
      "cell_type": "code",
      "source": "submission = pd.DataFrame.from_dict(predictions)\nsubmission.to_csv('preds.csv', index=False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "mimetype": "text/x-python",
      "version": "3.6.4",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "pygments_lexer": "ipython3",
      "name": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}